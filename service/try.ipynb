{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルを読み込む\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import feedparser\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "processed_news_file = \"processed_news.json\"\n",
    "\n",
    "\n",
    "def load_processed_news():\n",
    "    if os.path.exists(processed_news_file):\n",
    "        with open(processed_news_file, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_processed_news(processed_news):\n",
    "    with open(processed_news_file, \"w\") as file:\n",
    "        json.dump(processed_news, file)\n",
    "\n",
    "\n",
    "def clean_old_news(processed_news, days=7):\n",
    "    threshold_date = datetime.now() - timedelta(days=days)\n",
    "    threshold_timestamp = int(threshold_date.timestamp())\n",
    "    return {k: v for k, v in processed_news.items() if v > threshold_timestamp}\n",
    "\n",
    "\n",
    "def get_rss_feeds(urls, processed_news):\n",
    "    all_entries = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            feed = feedparser.parse(url)\n",
    "            if feed.bozo:\n",
    "                logger.error(f\"Failed to parse feed: {url}\")\n",
    "            else:\n",
    "                for entry in feed.entries:\n",
    "                    link = entry.get(\"link\")\n",
    "                    if link and link not in processed_news:\n",
    "                        all_entries.append(entry)\n",
    "                        processed_news[link] = int(datetime.now().timestamp())\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching feed {url}: {e}\")\n",
    "    return all_entries\n",
    "\n",
    "\n",
    "def filter_ai_news(feed_entries):\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        logger.error(\"OpenAI API key is not set.\")\n",
    "        return []\n",
    "\n",
    "    openai.api_key = openai_api_key\n",
    "    client = OpenAI()\n",
    "\n",
    "    filtered_entries = []\n",
    "\n",
    "    for entry in feed_entries:\n",
    "        title = entry.title\n",
    "        description = entry.get(\"description\", \"\")\n",
    "        content = entry.get(\"content\", \"\")[:300]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "与えられた文章が、以下の条件に合致する場合は1、そうでない場合は0を出力せよ。結果は0か1のみを出力すること。\n",
    "# 条件\n",
    "[LLM, 生成AI, 生成系AI, 基盤モデル, 大規模言語モデル, ChatGPT, OpenAI, Gemini, Claude, RAG]のいずれかに深く関連すること。\n",
    "# 文章\n",
    "{title}\n",
    "{description}\n",
    "{content}\n",
    "# 結果\n",
    "result=\n",
    "\"\"\"\n",
    "        logger.debug(f\"filter_prompt: {prompt}\")\n",
    "\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\", messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "            )\n",
    "            ai_decision = completion.choices[0].message.content.strip()\n",
    "            if ai_decision == \"1\":\n",
    "                filtered_entries.append(entry)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in AI filtering: {e}\")\n",
    "\n",
    "    return filtered_entries\n",
    "\n",
    "\n",
    "def summarize_news(news_entries, processed_news):\n",
    "    summaries = []\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        logger.error(\"OpenAI API key is not set.\")\n",
    "        return summaries\n",
    "\n",
    "    openai.api_key = openai_api_key\n",
    "    client = OpenAI()\n",
    "\n",
    "    for entry in news_entries:\n",
    "        link = entry.get(\"link\")\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "以下の記事のContentをFormatに従って要約して下さい。\n",
    "<制約条件>\n",
    "- 要点は3~5つに絞って下さい。\n",
    "- 日本語で要約して下さい。\n",
    "- Formatの内容以外のことは出力しないでください。\n",
    "<Format>\n",
    "```\n",
    "{{記事全体の要約を100字程度で出力する}}\n",
    "```\n",
    "1. *{{要点1見出し}}* ：{{要点1のまとめ}}\n",
    "2. *{{要点2見出し}}* ：{{要点2のまとめ}}\n",
    "...\n",
    "n. *{{要点n見出し}}* ：{{要点nのまとめ}}\n",
    "<Content>\n",
    "{entry.title}\n",
    "{entry.get('content', '')}\n",
    "\"\"\"\n",
    "            logger.debug(f\"summary_prompt: {prompt}\")\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\", messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "            )\n",
    "            summaries.append(\n",
    "                {\n",
    "                    \"title\": entry.title,\n",
    "                    \"summary\": completion.choices[0].message.content,\n",
    "                    \"link\": entry.link,\n",
    "                }\n",
    "            )\n",
    "            processed_news[link] = int(datetime.now().timestamp())\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing news: {e}\")\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def send_to_slack(summaries, webhook_url):\n",
    "    if not webhook_url:\n",
    "        logger.error(\"Slack Webhook URL is not set.\")\n",
    "        return\n",
    "\n",
    "    for summary in summaries:\n",
    "        try:\n",
    "            message = {\n",
    "                \"text\": f\"*<{summary['link']}|{summary['title']}>*\\n{summary['summary']}\",\n",
    "                \"unfurl_links\": True,\n",
    "            }\n",
    "            response = requests.post(webhook_url, json=message)\n",
    "            if response.status_code != 200:\n",
    "                logger.error(f\"Failed to send message to Slack: {response.status_code}\")\n",
    "\n",
    "            logger.debug(f\"message: {message}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sending to Slack: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 環境変数のチェック\n",
    "    slack_webhook_url = os.getenv(\"SLACK_WEBHOOK_URL\")\n",
    "    if not slack_webhook_url:\n",
    "        logger.error(\"Slack Webhook URL is not set.\")\n",
    "        return\n",
    "\n",
    "    # 処理済みニュースの読み込み\n",
    "    processed_news = load_processed_news()\n",
    "\n",
    "    # 古いニュースを削除\n",
    "    processed_news = clean_old_news(processed_news)\n",
    "\n",
    "    # 複数のRSSフィードからニュースを取得\n",
    "    rss_urls = [\n",
    "        \"https://qiita.com/popular-items/feed\",\n",
    "        # \"https://gigazine.net/news/rss_2.0/\",\n",
    "        # \"https://b.hatena.ne.jp/entrylist/it.rss\",\n",
    "        # \"https://dev.classmethod.jp/feed/\",\n",
    "        # \"https://news.microsoft.com/ja-jp/feed/\",\n",
    "        # \"https://aws.amazon.com/jp/about-aws/whats-new/recent/feed/\",\n",
    "        # \"https://zenn.dev/feed\",\n",
    "    ]\n",
    "    print(f\"Fetching RSS feeds from {len(rss_urls)} sources.\")\n",
    "    feed_entries = get_rss_feeds(rss_urls, processed_news)\n",
    "    print(f\"Fetched {len(feed_entries)} new entries from RSS feeds.\")\n",
    "\n",
    "    # ニュースから生成AIに関連するものを抽出\n",
    "    print(\"Filtering AI-related news...\")\n",
    "    ai_related_entries = filter_ai_news(feed_entries)\n",
    "    print(f\"Filtered down to {len(ai_related_entries)} AI-related entries.\")\n",
    "\n",
    "    # ニュースのサマリを生成\n",
    "    print(\"Generating summaries for filtered news...\")\n",
    "    summaries = summarize_news(ai_related_entries, processed_news)\n",
    "    print(f\"Generated summaries for {len(summaries)} entries.\")\n",
    "\n",
    "    # 処理済みニュースの保存\n",
    "    save_processed_news(processed_news)\n",
    "    print(\"Saved processed news data.\")\n",
    "\n",
    "    # サマリをSlackに送信\n",
    "    print(\"Sending summaries to Slack...\")\n",
    "    send_to_slack(summaries, slack_webhook_url)\n",
    "    print(\"Summaries sent to Slack.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching RSS feeds from 1 sources.\n",
      "Fetched 30 new entries from RSS feeds.\n",
      "Filtering AI-related news...\n",
      "Filtered down to 2 AI-related entries.\n",
      "Generating summaries for filtered news...\n",
      "Generated summaries for 2 entries.\n",
      "Saved processed news data.\n",
      "Sending summaries to Slack...\n",
      "Summaries sent to Slack.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
