Tweet Share Hatena 言語モデルの進化は、単なるテキスト生成から、より高度な「理解」へとシフトしています。今回行われた研究では、大規模言語モデル（LLM）が単に次のテキストを生成するための統計（確率）を計算しているだけでなく、物事がどのように位置づけられ、時間がどのように進行するかを「理解」している可能性が新たに示されました。 なお、本研究は野心的なテーマに挑んでいるため、大きな命題に対する断定的な結論が得られているわけではありません。しかし、それでも一見の価値がある報告内容となっています。 （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 本研究は、マサチューセッツ工科大学（MIT）の研究者によって行われました。彼らの研究は、LLMが実際に「世界モデル」を形成している可能性を示しています。世界モデルとは、現実世界の動きを把握するための内部的なフレームワークです。 参照論文情報 タイトル：Language Models Represent Space and Time 著者：Wes Gurnee, Max Tegmark 所属：MIT URL：https://doi.org/10.48550/arXiv.2310.02207 https://twitter.com/ai_database/status/1710128426768883838 関連研究（続きは記事の末尾にあります） ■ GPT-4などのLLMが「AはB」から「BはA」を導かない『逆転の呪い』における誤解なき解釈と対策 ■ 推論能力をさらに強める戦略『AoT』で、LLMが「直感」に似た能力を示すようになった ■ GPT-4に選択肢を与えるとき、順序を入れ替えるだけで性能に大きな変化があることが明らかに 従来の課題 LLMの目的と”理解” 大規模言語モデル（LLM）は、基本的に「テキストの次のトークンを予測する」という目的で訓練されています。しかし、これらのモデルは単なるテキスト生成以上の能力を示しており、”理解”に似た挙動が見られます。 LLMが何をどう理解しているのかは、非常に不明確です。とは言え、LLMは単に大量の相関関係を学習した結果を出力しているだけではなく、独自のデータ生成プロセスを持っている可能性が指摘されています。 研究の背景と疑問点 LLMの高い能力が明るみになるにつれて、疑問も増しています。LLMが世界に対するモデルを形成しているのか、それとも単に表面的な統計情報を学習・出力しているのかという疑問です。 既存の研究では、LLMがゲームの状態や色、空間に関する知識を持っていることが示されています。しかし、これらの研究は主に特定のドメインに焦点を当てており、LLMがどのように「世界モデル」を形成しているのかについては明らかにされていません。 研究方法 （自社サービス広告②）AIDBのリサーチを貴社のニーズに合わせてサブスクしませんか？ 目的とアプローチ 今回、MITの研究者らによって、LLMが「空間と時間に対する理解」を持っているかどうかが調査されました。研究者らは、この問いに答えるために、特定の方法論を採用しています。 データセットの選定 （自社サービス広告③）AIDBで貴社のサービスをブランディングしませんか？ 研究者らは、6つの異なるデータセットを用意しました。世界、米国、NYCの地名、歴史的人物、芸術作品、ニュースヘッドラインなどが含まれています。データセットは、LLMが空間と時間に対する理解を持っているかどうかを評価するための基盤となります。 モデルの選択：Llama-2ファミリー この研究で使用されたモデルは、Llama-2ファミリーに属しています。 Llama-2とは、Facebook Researchによって開発された大規模な言語モデルであり、7Bから70Bのパラメーター範囲で提供されています。元々のLlama-1からアップデートされ、新しい公開データのミックスで訓練されています。 Llama-2は、安全性と有用性に重点を置いて設計されており、多くのベンチマークテストで既存のオープンソースのチャットモデルを上回っています。なお、対話用途に最適化されたバージョンであるLlama-2-Chatも提供しています。 補助的なモデル（線形／非線形回帰プローブ）の活用 本研究では線形回帰プローブと非線形回帰プローブを用いて実験が進められました。 プローブの目的と機能 今回使用されたプローブは、LLMの内部活性化に基づいて、エンティティ（場所やイベント）の実際の世界の位置または時間を予測する補助的なモデルです。LLMが空間と時間に対するどのような「理解」を持っているのかが評価されます。 プローブは、各モデル、データセット、レイヤーで訓練され、その性能はR2値で評価されます。線形的な対応関係を測る「線形回帰プローブ」と線形的な対応関係を測る「非線形回帰プローブ」が用意されました。 線形回帰プローブの詳細 線形回帰プローブは、LLMの内部状態（活性化）から目的変数（この場合は空間や時間の情報）を予測するための線形（直線的な関係性）モデルです。このプローブは、特定の特徴量（例えば、場所や時間）がモデル内でどのように線形的に表現されているかを評価するために使用されます。 非線形回帰プローブとの比較 非線形回帰プローブは、より複雑な関係性を捉える能力があります。ただし、この研究ではその性能の向上は限定的でした。 線形プローブと非線形プローブの選択は、研究の目的や評価する特徴に依存します。この研究では、どちらも使用され、線形プローブが空間と時間の連続的な特徴に対しても高い性能を示しいました。詳細は後述します。 実験結果 線形プローブの優れた性能 研究では、線形プローブが非線形プローブよりも優れた性能を示していました。具体的には、線形プローブと非線形プローブ（一層のMLP）を比較した結果、R2値（決定係数）において線形プローブが高い性能を発揮したことが報告されています。これは、空間や時間の情報が線形的に（または少なくとも線形的に解読可能で）表現されているという証拠とされます。 研究では、さまざまなデータセットとモデルに対してR2値を計測しました。その結果、非線形プローブの使用によるR2値の改善は最小限であり、線形プローブが十分に高い性能を発揮していることが確認されました。 空間と時間の理解度の限界点 研究では、LLMのニューラルネットワークにおける階層を半分まで進んだところで、空間と時間の理解度が向上すると報告されています。その後、性能は限界点に達するとされています。 空間と時間の特徴は、モデルの階層が進むにつれて品質が向上しますが、階層の半分を超えると、その品質はプラトー（限界点）に達することが観測されました。 研究者らの考察と結論 LLMの空間と時間に対する理解 本記事を読むにはAIDBのアカウントが必要です。ログイン 無料会員登録※ログイン/初回登録後、下記ボタンを押してください。 ■サポートのお願い AIDBを便利だと思っていただける方に、任意の金額でサポートしていただけますと幸いです。 AI新着論文を自動で取得し、日本語サマリーを毎日メールで受け取るサービスに申し込みが殺到しています。 毎日新しく出版されるAIの論文にキャッチアップするのは、「手間がかかる」「読解が難しい」といった問題あります。 AIDBは、オートで新着論文の探索を行い、❶論文情報❷日本語サマリーを複数掲載するニュースレターサービスを行っています。 ■サービス概要 ① AI新着論文の情報を毎日5件自動で収集 ② 論文のサマリーを記載 ③ キーワードをカスタマイズ可能 ④ 受け取り時間帯を指定可能 下記のフォームから簡単に申し込みが開始できます。 価格は現在¥500/月で、3日間は無料でトライアルができます。 キーワードを詳細にカスタマイズしたり、受け取り時間帯を指定するには、こちらのページから申し込みを行なってください。 下記のボタンからトライアルを開始した場合、デフォルトの設定（生成AI関連の論文）でサービスをご提供します。 キーワードや時間帯のご変更は申し込み後も可能です。 ※初めの3日間は無料です。4日目から引き落としを開始いたします。 Δ Tweet Share Hatena