最終更新日：2023/10/26 「ステップバイステップで考えてください」といったプロンプトで知られるChain-of-Thought（CoT）手法に匹敵する性能を持つプロンプト手法『Inferential Exclusion Prompting（IEP）』が研究者たちによって開発されました。IEPは大規模言語モデル（LLM）に非線形的な思考をさせることを目的としています。 IEPは、さまざまなタスクでCoTを上回る性能を示しています。また、さらに興味深いことに、CoTと統合することで、その効果はより一層高まる場合があります。 この研究は、カリフォルニア大学やペンシルバニア大学などの研究者によって行われました。 （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 参照論文情報 ・タイトル：Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs’ Non-linear Thinking・著者：Yongqi Tong, Yifan Wang, Dawei Li, Sizhe Wang, Zi Lin, Simeng Han, Jingbo Shang・所属：University of California San Diego, University of Pennsylvania, University of Southern California, Yale University・URL：https://doi.org/10.48550/arXiv.2310.12342 目次 Toggle 従来の課題や背景CoTの特徴と単一で使用する際の限界誤差の伝播単一思考の制限IEPのフレームワーク主要なステップ非線形とは？本研究との関連性IEPメソッドの性能テストベンチマークの導入（MARB）MARBの特性なぜMARBが必要かテストの結果IEP対CoTの性能比較IEPとCoTの統合その他の観察点実行方法・使い方プロンプトテンプレートの導入プロンプトテンプレートの具体例プロンプトの成り立ちまとめ 従来の課題や背景 CoT（Chain-of-Thought）テクニックがPaLM2というモデルに誤りを引き起こさせる一例 CoTの特徴と単一で使用する際の限界 Chain-of-Thought（CoT）は、LLMに推論能力を付与するための一般的な手法です。CoTは線形的な（直線的な）推論を実行させます。簡単に言うと「Aが真ならばBが真」といった形の推論を行わせることが多いです。 CoTは、問題解決の過程を一連のステップに分解し、それぞれのステップで特定の推論を行わせます。例えば、「雨が降っているなら、傘を持つべきだ」というような線形的な推論がCoTの一例です。質問応答（QA）タスクなどでよく使用されます。 しかし、このアプローチにはいくつかの問題点があります。 誤差の伝播 CoTは一つの思考のステップが次のステップに影響を与えるという連鎖的な構造を持っています。そのため、中間のステップで生じたわずかな誤差が、連鎖全体に伝播してしまう可能性があります。 CoTの中間ステップの評価は困難であり、最終的な答えだけが評価される傾向があります。中間ステップでの不適切な推論が検出されず、推論の信頼性が低下する場合があります。 単一思考の制限 CoTは段階的な推論を実行させるため、多角的な視点や非線形的な思考が疎かにされがちです。複雑な問題に対する多面的な解決策が見落とされる可能性があります。 「非線形」とは？という疑問に対しては後述します。 現実世界の問題は、しばしばCoTのような線形的な推論では解決できないほど複雑です。一方で、われわれ人間の思考は、直感的な発散思考や逆転思考を用いて、多角的な解決策を模索しています。 以上のように、CoTは多くの有用な側面を持ちつつも、その限界と課題が明らかになっています。これらの問題を解決し、LLMの推論能力をさらに高めるためには、新しいフレームワークと手法が必要です。 本記事の関連研究：LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト IEPのフレームワーク IEP（Inferential Exclusion Prompting）のステップを人間の意思決定プロセスに触発された形で示している図 （自社サービス広告②）AIDBのリサーチを貴社のニーズに合わせてサブスクしませんか？ 今回研究者たちは、LLMに高度な推論能力を持たせる新しいフレームワーク、『Inferential Exclusion Prompting（IEP）』を提案しています。複雑な問題解決において、従来のCoT方式の限界を超えることを目的としています。 主要なステップ IEP（Inferential Exclusion Prompting）のアルゴリズムを構造的に記述したもの （自社サービス広告③）AIDBで貴社のサービスをブランディングしませんか？ IEPフレームワークは主に以下の3つのステップから成り立っています。 ① 計画（Planning） まず、問題を理解し、複数の可能な回答を生成します。与えられたコンテキストや既知の事実に基づいて、LLMが複数の候補回答を生成します。 ② 推論（Inferring） 次に、各候補回答の前提を確認します。このステップでは、「もし候補が真であれば、その前提は何か？」といった形でプロンプトが行われます。前提がコンテキストや既知の事実と一致する場合、その候補は有効とされます。 ③ 除去（Eliminating） 最後に、前提に矛盾する候補を除外します。このステップでは、各候補が前提と矛盾するかどうかを評価し、矛盾する場合は候補から除外されます。最終的に最も確からしい回答だけが残されます。 IEPフレームワークは、複雑な問題に対して多角的な視点からアプローチできる点が強みです。このフレームワークによって、LLMは従来のCoT方式よりも高度な推論能力を発揮することが期待されています。 本記事の関連研究：GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク『LogiCoT』と実行プロンプト 非線形とは？本研究との関連性 非線形（Non-linear）とは、入力と出力が直線的な関係にないものを指します。線形（Linear）な関係では、入力が2倍になれば出力も2倍になるような単純な関係があります。しかし、非線形の場面では、そのような直線的な関係が成り立たない場合が多いです。 わかりやすく言えば、線形的は直線的で、非線形的は曲線的です。 従来のCoTテクニックは、線形的な思考を行わせるものでした。一方で、本研究のIEPは、非線形的な思考を促進するフレームワークです。 IEPは線形的な制約を打破し、複数の選択肢や前提を考慮する非線形的な推論を可能にすることを目的にしています。非線形的な推論を使用すると、人間の複雑な思考パターンをより正確に模倣すると考えられます。 IEPメソッドの性能テスト ベンチマークの導入（MARB） IEPの性能を評価するために、研究者らは新しいベンチマーク「Mental-Ability Reasoning Benchmark（MARB）」を導入しました。このベンチマークは、合計で9,115の質問を含む6つの新しいサブタスクから成り立っています。MARBは、人間の論理と言語理解の革新的な側面を反映するように設計されています。 Mental-Ability Reasoning Benchmark（MARB）からのいくつかの代表的な例 MARBの特性 サブタスクの多様性 MARBは、parajumbles（文の並び替え）、謎解き、パズル、頭の体操、および批判的推論クエリなど、多様なゲームと課題から成り立っています。 教育者による設計 MARBのデータセットの大部分（84.54%）は、長年の教育経験を持つ教育者によって提供された理由付けを含んでいます。 なぜMARBが必要か 既存の推論ベンチマーク（CommonsenseQA、OpenbookQA、StrategyQA、LogiQAなど）は、しばしば人間の認知プロセスの狭い部分にフォーカスしています。そのため、精神的能力に焦点を当てた一般的なベンチマークの必要性が高まっていました。 本記事の関連研究：GPT-4をセラピストとして実行し、「認知の歪み」を診断させるためのフレームワーク『Diagnosis of Thought (DoT)』と実行プロンプト テストの結果 表1：PaLM2-540Bが既存のベンチマークでどれだけ正確に動作するかを、異なるプロンプトスキルを用いて評価表2：PaLM2-540BとGPT4がMARBでどれだけ正確に動作するかを評価 IEP対CoTの性能比較 IEPは、多様なタスクにおいてCoTを一貫して上回る性能を示しました。特に、OpenbookQAというタスクでは、IEPはCoTを6.32%も上回りました。OpenbookQAは関連する常識や事実を明示的に指定しており、IEPがそのようなタスクで優れていることを示しています。 IEPとCoTの統合 IEPとCoTを統合することで、特定のタスクでさらに性能が向上することが確認されました。なお、そもそもCoTのアプローチがすべてのシナリオで有益であるわけではないことにも注意が必要です。例えば、LogiQAというタスクでは、CoTはゼロショットのベースラインよりも性能が低かったというデータがあります。 その他の観察点 CoTは特定のタスク、特に「謎解き（Riddles）」において、IEPよりも優れた性能を示す場合があります。これは、謎解きが人間の認知において「ひらめき」や「突然の洞察」を強調するため、IEPの緻密で構造化された推論特性とは必ずしも一致しないからです。 本記事の関連研究：LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト 実行方法・使い方 プロンプトテンプレートの導入 IEPを実行する際にはプロンプトテンプレートが使用可能です。テンプレートは、質問と回答の一連の流れを通じて、IEPの3つの主要なステップ（計画、推論、除去）を効果的に反映するものです。 プロンプトテンプレートの具体例 以下は、IEPを実行するためのプロンプトテンプレートの具体例です。 ユーザー：[複数の選択肢が回答されるように質問] LLM：[複数の選択肢を回答] ユーザー：もしその推論が真だとすれば、前提は何ですか？ LLM：〜〜〜 ユーザー：さきほどの選択肢は、それらの前提と矛盾しますか？ LLM：〜〜〜 ユーザー：最終的な答えは何ですか？ LLM：〜〜〜 プロンプトの成り立ち IEPは計画（Planning）、推論（Inferring）、除去（Eliminating）の3つの主要なステップで構成されます。可能な解の文脈、常識、または事実との含意関係を推測することで、より広い視点を提供します。 なお、上記の各ユーザープロンプトにおいて「ステップバイステップで考えてください」を取り付けることで、さらに強力になる場合もあるとのことです。（前章「テストの結果」参照） 本記事の関連研究：プロンプトを遺伝的アルゴリズムで自動最適化するプロンプトエンジニアリング手法『Promptbreeder（プロンプトブリーダー）』 まとめ この記事では、大規模言語モデル（LLM）の推論能力を向上させる新しいフレームワーク、Inferential Exclusion Prompting（IEP）について詳しく解説しました。IEPは、従来のCoT（Chain of Thought）テクニックの限界を克服し、非線形的な思考を可能にします。IEPのフレームワークは、計画（Planning）、推論（Inferring）、除去（Eliminating）の3つの主要なステップから成り立っています。 性能テストでは、新しいベンチマーク「Mental-Ability Reasoning Benchmark（MARB）」を用いて、IEPがCoTをほとんど一貫して上回る性能を示したことが確認されました。さらに、IEPとCoTを統合することで、特定のタスクでさらに性能が向上することも示唆されています。 実行方法としては、特定のプロンプトテンプレートを用いることで、IEPのフレームワークを効果的に活用できます。テンプレートは、LLMが複数の選択肢を考慮し、最も整合性のある答えを導き出すために設計されています。 