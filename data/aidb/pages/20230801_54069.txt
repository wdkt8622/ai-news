Tweet Share Hatena AI研究の最前線に立つDeepMindが新たな技術「RT-2」を開発しました。この技術は、ロボットが初めて見る環境で、初めて聞く指示に対しても適切な行動をとれるようにするものです。 参照論文情報 タイトル：RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control 著者：Anthony Brohan, Noah Brown, Justice Carbajal et al. 所属：Google DeepMind URL：https://robotics-transformer2.github.io/assets/rt2.pdf GitHub：https://robotics-transformer2.github.io/ （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 関連研究 仮想世界でサッカーを学んだロボットが実世界で上手にサッカーをプレイ DeepMindが研究報告 DeepMindのタンパク質構造予測AI「AlphaFold」は進化を続けている 【DeepMind】AIの研究と「心理学の研究」の違いを語る RT-2とは何か？ RT-2は、視覚と言語の情報を同時に処理し、それぞれの情報から得られる情報を統合して行動を生成する技術です。インターネット規模のデータで訓練した視覚言語モデルをロボットに組み込むことで、ロボットが人間が行うような複雑なタスクを自然かつ効率的に実行できるようになります。 RT-2はロボットの行動を言語化し、視覚と言語のデータを一緒に訓練します。 視覚と言語の統合 RT-2の最大の特徴は、視覚と言語の情報を同時に処理する能力です。これにより、ロボットは視覚的な情報と言語的な指示を一度に理解し、それらを統合して適切な行動を生成することができます。 推論能力 RT-2は、ユーザーの指示をステップバイステップで推論する能力を備えています。例えば、「疲れた人に飲み物を運ぶ」というタスクにおいてエナジードリンクを選ぶなどの行動をとることができます。 RT-2は推論や記号理解、人間認識の実世界の状況に対応します。 （自社サービス広告②）AIDBのリサーチを貴社のニーズに合わせてサブスクしませんか？ 技術的な特徴 RT-2は、一般化の強化と意味的な推論の実現を目指しています。以下では、RT-2の主な技術的な特徴について詳しく説明します。 ビジョン-ランゲージ-アクションモデル RT-2は、ビジョン-ランゲージ-アクションモデル（VLAモデル）という新たなカテゴリのモデルを提案しています。これは、視覚と言語の両方を入力として取り、自然言語のトークンを生成するために訓練されたビジョン-ランゲージモデルを、ロボットのアクションを出力するように訓練するというアプローチを採用しています。 ロボットのアクションをテキストトークンとして表現し、それらを自然言語のトークンと同じようにモデルの訓練セットに直接組み込むことで、これを実現しています。このアプローチにより、ビジョン-ランゲージモデルは、ロボットの観測をアクションにマッピングする学習と、Webからの大規模な事前訓練の利点を享受する、一つのエンドツーエンド訓練モデルとして機能することが可能となります。 ロボットアクションの微調整 RT-2では、ビジョン-ランゲージモデルを制御するために、それらを訓練してアクションを出力するようにします。これを実現するために、アクションをモデルの出力のトークンとして表現します。これらのアクションのトークンは、言語のトークンと同じように扱われます。 アクションをテキストトークンに変換し、それらをカメラの観察とペアになったロボットの指示に「応答する」”マルチモーダルな文”を作成することで、ビジョン-ランゲージモデルを直接訓練して、指示に従うロボットのポリシーとして機能するようにします。 リアルタイム推論 現代のビジョン-ランゲージモデルのサイズは、数十から数百億のパラメータに達することがあります。このような大きなモデルをリアルタイムのロボット制御に直接使用することは現実的ではありません。そこで、RT-2では、モデルをマルチTPUクラウドサービスにデプロイし、ネットワーク経由でこのサービスをクエリすることで、リアルタイム制御を可能にしています。 このソリューションにより、適切な制御周波数を達成するとともに、同じクラウドサービスを使用して複数のロボットをサービスすることができます。最大のモデルである55BパラメータのRT-2-PaLI-X-55Bモデルは、1-3Hzの周波数で動作することができます。その小型版であるRT-2-PaLI-X-1.5Bモデルは、より高い周波数で動作することができます。 データ収集と訓練 RT-2の訓練データは、実世界のロボット操作から収集されます。これには、人間がロボットを遠隔操作する「テレオペレーション」のセッションが含まれます。これらのセッションでは、人間のオペレータがロボットに指示を出し、ロボットがそれに従って行動します。このプロセスを通じて、ロボットの観測、人間の指示、ロボットのアクションという3つの要素が結びつきます。 これらのデータは、ビジョン-ランゲージ-アクションモデルの訓練に使用されます。具体的には、ロボットの観測と人間の指示をモデルの入力とし、ロボットのアクションをモデルの出力とします。この訓練プロセスは、大量のデータと強力な計算リソースを必要とします。 RT-2は本当に優秀なのか？ RT-2の有効性を検証するために、研究者らは一連の実験を行いました。これらの実験は、RT-2が新たなオブジェクト、背景、環境に対してどの程度一般化できるか、そしてRT-2がどのような新たな能力を発揮できるかを評価することを目的としています。 評価に使用される一般化シナリオの例。 （自社サービス広告③）AIDBで貴社のサービスをブランディングしませんか？ 本記事を読むにはAIDBのアカウントが必要です。ログイン 無料会員登録※ログイン/初回登録後、下記ボタンを押してください。 ■サポートのお願い AIDBを便利だと思っていただける方に、任意の金額でサポートしていただけますと幸いです。 AI新着論文を自動で取得し、日本語サマリーを毎日メールで受け取るサービスに申し込みが殺到しています。 毎日新しく出版されるAIの論文にキャッチアップするのは、「手間がかかる」「読解が難しい」といった問題あります。 AIDBは、オートで新着論文の探索を行い、❶論文情報❷日本語サマリーを複数掲載するニュースレターサービスを行っています。 ■サービス概要 ① AI新着論文の情報を毎日5件自動で収集 ② 論文のサマリーを記載 ③ キーワードをカスタマイズ可能 ④ 受け取り時間帯を指定可能 下記のフォームから簡単に申し込みが開始できます。 価格は現在¥500/月で、3日間は無料でトライアルができます。 キーワードを詳細にカスタマイズしたり、受け取り時間帯を指定するには、こちらのページから申し込みを行なってください。 下記のボタンからトライアルを開始した場合、デフォルトの設定（生成AI関連の論文）でサービスをご提供します。 キーワードや時間帯のご変更は申し込み後も可能です。 ※初めの3日間は無料です。4日目から引き落としを開始いたします。 Δ Tweet Share Hatena