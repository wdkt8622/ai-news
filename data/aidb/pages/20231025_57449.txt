最終更新日：2023/10/25 スタンフォード大学などの研究者らによる最新の研究では、Nature誌をはじめとする約4,800本の論文に対して、GPT-4を用いた査読の品質が大規模に検証されました。この研究は、科学的なフィードバックの生成における大規模言語モデル（LLM）の有用性を改めて（あるいは初めて）体系的に評価するものです。 結果からは、「LLMは査読サポートツールとしても有用」という結論が導かれました。また論文の初期段階での推敲においても、LLMのフィードバックが研究者に有益である可能性は高いとされています。 本記事では、研究内容を詳しく見ていきます。 （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 参照論文情報 ・タイトル：Can large language models provide useful feedback on research papers? A large-scale empirical analysis・著者：Weixin Liang, Yuhui Zhang, Hancheng Cao, Binglu Wang, Daisy Ding, Xinyu Yang, Kailas Vodrahalli, Siyu He, Daniel Smith, Yian Yin, Daniel McFarland, James Zou・所属：Stanford University, Northwestern University, Cornell University・URL：https://doi.org/10.48550/arXiv.2310.01783・GitHub：https://github.com/Weixin-Liang/LLM-scientific-feedback 目次 Toggle 従来の課題と背景実験デザイン1. 査読の自動化：GPT-4の活用2. 対象となる論文3. フィードバックの構造4. フィードバックの評価5. ユーザースタディ実験の結果1. GPT-4と人間のレビュアーとの重複率2. 人間レビュアー同士との比較3. 論文の品質と重複率4. 研究者の評価実用性の考察1. 一回のパスでのフィードバック生成2. ユーザー体験と効率性3. 実用性への制限プロンプト例1. プロンプトの設計2. プロンプトの内容主な結論と注意点1. LLMのフィードバックは有益2. 専門家のフィードバックが得られにくい分野での有用性3. 初期段階での有用性4. 特定の側面に焦点を当てる傾向5. 深い批評は難しいまとめ 従来の課題と背景 査読は、研究業界において基盤となるプロセスです。研究の品質は、専門家による厳密な評価を通じて保証されるのが慣習となっています。 査読は非常に時間と労力を要するプロセスであり、一年間で約100Mの研究者時間と$2.5B USドルが費やされています。 一方で、近年、科学的な論文の数は急速に増加しています。例えば、ICLR（機械学習の国際会議）への論文提出数は、2018年の960本から2023年には4,966本へと増加しています。 さらに研究の専門分野が多角化するにつれて、適切な査読者を見つけることがますます困難になっています。 研究が急速に進展する現代においては、査読のスピードも非常に重要です。しかし、上記のような事情から、高品質な査読を速やかに行うことは容易ではありません。 加えて、比較的予算の小規模な研究機関や、資源に限りのある地域での研究者は、高品質なフィードバックを得るのは一層困難です。 本記事の関連研究：AIが科学論文の査読を補助する日は近い？ 実験デザイン GPT-4をベースにした科学的フィードバック生成パイプライン 1. 査読の自動化：GPT-4の活用 研究者らはGPT-4を用いて科学論文の査読を自動化するための仕組みを構築しました。仕組みは、LLMが論文のPDF全体に対してコメントを生成するように設計されています。まず分析過程においては論文のタイトル、要約、図表のキャプション、および本文を解析してプロンプトが構築され、その後GPT-4によって構造化されたコメントが生成されます。 2. 対象となる論文 実験では、Nature誌とICLR（機械学習の国際会議）の論文が対象とされました。合計で約4,800本の論文がこの実験の対象となり、これらの論文に対する人間による約15,000件のレビューとLLM生成コメントとの比較が行われました。 （自社サービス広告②）AIDBのリサーチを貴社のニーズに合わせてサブスクしませんか？ 3. フィードバックの構造 GPT-4には、科学的なフィードバックを構造化するように指示が与えられました。次の4つのフィードバックセクションが設定されました。：「重要性と新規性」、「受理の可能性」、「却下の可能性」、「改善の提案」 4. フィードバックの評価 フィードバックの品質を評価するために、研究者らは二段階のコメントマッチングパイプラインを開発しました。まず抽出型テキスト要約を用いてLLMと人間によるフィードバックからコメントのポイントを抽出し、次にセマンティックテキストマッチングを行って、LLMと人間のフィードバック間で共有されるコメントのポイントをマッチさせます。 5. ユーザースタディ さらに、308人の研究者を対象にしたユーザースタディも行われました。この調査では、研究者が自分自身の論文に対するGPT-4システムによるフィードバックをどのように評価するかが確認されました。 このように、研究者らは非常に綿密な実験デザインを用いて、LLMが科学的な査読にどれだけ貢献できるのかを詳細に検証しました。 本記事の関連研究：テキストから科学的な図を生成する新手法「FigGen」登場 実験の結果 人間とLLMによるコメントの11の側面に関する相対頻度 （自社サービス広告③）AIDBで貴社のサービスをブランディングしませんか？ 1. GPT-4と人間のレビュアーとの重複率 研究者らは、GPT-4によるフィードバックと人間によるフィードバックの間で提起されたポイントの平均的な重複率を計測しました。Nature誌においては、この重複率は30.85%でした。また、ICLR（機械学習の国際会議）においては、重複率は39.23%でした。 2. 人間レビュアー同士との比較 上記の数値は、人間のレビュアー同士での平均的な重複率と比較しても優れています。Nature誌での人間同士の重複率は28.58%、ICLRでのそれは35.25%です。 ※ただし、人間同士の重複率（および人間とLLMの重複率）は分野によって大きく上下する可能性があります。 3. 論文の品質と重複率 さらに興味深いことに、品質が比較的低いと定性的に判断される（ICLRで却下された）論文の場合、GPT-4と人間のレビュアーとの間の重複率はさらに高く、平均で43.80%に達しました。 4. 研究者の評価 この研究では、308人の研究者（主にAIと計算生物学の分野）からのフィードバックも収集されました。その結果、57.4%の研究者がGPT-4によるフィードバックを「有用/非常に有用」と評価し、82.4%がそれを少なくとも一部の人間のレビュアーよりも有益だと感じました。 上記の結果は総じて、GPT-4が査読プロセスにおいて有用なフィードバックを提供できる可能性を示しています。 本記事の関連研究：新しい科学的方程式を導くための機械学習ツール プリンストン大の研究者が発表 実用性の考察 1. 一回のパスでのフィードバック生成 GPT-4による査読プロセスは、非常に効率的な方法で行われます。論文のPDFを読み込んだ後、フィードバックを生成するためのプロンプト指示を一度だけ与えるという2ターンの対話で完結します。プロセスがシンプルなため、査読のスピードを大幅に向上させる可能性があります。 2. ユーザー体験と効率性 フィードバック生成は一回のパスで出力できるため、ユーザーにとって非常に便利です。研究者は、自分が著した論文のPDFをシステムにアップロードするだけで、短時間で査読のようなコメントを受け取ることができます。初めて論文を提出する研究者や、フィードバックを速やかに必要としている研究者にとって特に有用だと考えられます。 3. 実用性への制限 ただし、この効率性が全てのケースで有用であるわけではありません。GPT-4は非常に高度なモデルであり、多くの場合で有用なフィードバックを提供できますが、それでも人間の専門家による査読には及ばない側面もあります。例えば、非常に専門的な内容や、新しい研究手法に対する詳細なフィードバックは、GPT-4が提供するものよりも、人間の専門家によるものが優れている場合があります。 本記事の関連研究：論文の大規模データセット「unarXive 2022」登場！ プロンプト例 1. プロンプトの設計 本研究では、GPT-4による科学的フィードバックを生成するためのプロンプトが設計されています。Nature誌やICLR（機械学習の国際会議）などの主要な学術誌と会議やフィードバックに基づく構造に従って作成されているとのことです。 2. プロンプトの内容 以下は査読のようなフィードバックを行わせるプロンプトの例です。 ユーザー： 上記の論文に対して、以下の観点から科学的レビューを行なってください。 1. サイエンスにおける重要性と新規性 2. 論文誌への受理の可能性 3. 論文誌からの却下の可能性 4. 改善のための提案 なお、項目2と3においては、各理由に2つ以上のサブポイントを用いて詳細に説明してください。 それぞれ以下のような役割を持ちます。 サイエンスにおける重要性と新規性: 論文が提供する新しい知見やその科学的な重要性について評価します。 論文誌への受理の可能性: 論文が受理される可能性が高いと考えられる理由を列挙します。 論文誌からの却下の可能性: 論文が却下される可能性が高いと考えられる理由を詳細に列挙します。 改善のための提案: 論文をより良くするための具体的な提案を行います。 上記のプロンプトにより、GPT-4は一回のパスで科学的フィードバックを生成することができ、レビュープロセスが効率的に行えます。 本記事の関連研究：ChatGPTで「論文から非常に正確なデータ抽出」ができるとの報告 主な結論と注意点 1. LLMのフィードバックは有益 研究者によるフィードバックとLLMによるフィードバックの間には、一定の一致性が確認されました。さらに65.3%の参加者はLLMのフィードバックが人間が見落とす可能性のある視点を提供していると感じました。 2. 専門家のフィードバックが得られにくい分野での有用性 研究者の間での自己選択の問題はあるものの、機械学習と計算生物学の研究者からのフィードバックでは、LLMが特に有用である可能性が高いと示唆されています。 3. 初期段階での有用性 LLMによるフィードバックは、論文の初期段階でのレイアウトや結果の提示においても有用である可能性があります。 4. 特定の側面に焦点を当てる傾向 ただしLLMは特定のプロンプトに基づいて動作するため、そのフィードバックは特定の側面に集中する可能性があります。「内容よりもテスト手法や機械学習の詳細に焦点を当てがち」との考察も出ています。 5. 深い批評は難しい LLMには、特定かつ実行可能なフィードバックを生成する能力に通常は限界があるとのことです。例えば機械学習の分野においては「モデルのアーキテクチャや設計に対する深い批評」を提供するのが難しいとされています。 まとめ GPT-4を用いた査読の品質に関する大規模な実験が行われ、その結果は人間のレビュアーと比較しても優れていることが確認されました。しかし、深い批評を提供するのは難しいなどの注意点もあります。今回の研究は、AIを用いた科学的査読の可能性を初めて具体的に示した重要な一歩であり、今後の研究に大いに期待が寄せられます。 LLMなどのAI技術・ツールを実際の査読で使用するべきかどうかは各論文誌や機関によって明確に定められている場合があり、現時点では主要な論文誌ではLLMによる査読を認めていない可能性が高いです。そのため、まだ現在においては、本研究はあくまで潜在的な価値を検証したものであると留意した方がよいと考えられます。 しかし、自身の研究を批評的な視点からレビューして推敲する目的などにおいては、すぐにでも活用する価値があるかもしれません。 