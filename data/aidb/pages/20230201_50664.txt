Tweet Share Hatena この記事では、スマートフォンの音声通話を加速度センサーから盗聴する技術についての研究を紹介します。米ペンシルバニア州立大の研究グループが実証実験をもとにリスクを警告しています。 （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 目次 セキュリティの穴をつくAIの悪用事例 事例1 ChatGPTを用いたマルウェア生成 事例2 ディープフェイクによる政治経済撹乱 内蔵センサーで通話盗聴 米ペンシルバニア州立大がリスク報告 加速度センサーデータへの自由なアクセスにはリスクあり センサーデータから音声を認識するAIモデルを実際に開発 まとめ 関連研究 セキュリティの穴をつくAIの悪用事例 AIが普及するにつれ、AIを悪用したハッキング等の脅威が現実のものになりつつあります。この新しいリスクを知り、対策を考えていく必要があります。記事の前段として、AIの悪用事例を挙げます。 事例1 ChatGPTを用いたマルウェア生成 最近世間を賑わせているChatGPTですが、ハッカー達による悪用が水面下で進んでいるようです。2022年12月、ハッカー達のネット上の溜まり場に、ChatGPT – Benefits of Malware（マルウェアにおける利点）というスレッドが立ち上がりました。このスレッドでは、ChatGPTを用いてマルウェアを再現する実験がおこなわれています。実験のうちいくつかでは、ChatGPTによるコード生成が成功し、マルウェアとして機能するプログラムが出来ています。 事例2 ディープフェイクによる政治経済撹乱 AIの得意技である「画像生成」「音声合成」を悪用する「ディープフェイク」は、いくつかの事件を起こしています。例えば、マレーシアの政治家のプライベートを撮影したとするディープフェイク動画が公開され、汚職疑惑での調査が要求されました。その結果、政権が不安定化しました。また、イギリスのとあるエネルギー会社は、CEOの声を真似たディープフェイク音声に騙され、約20万ポンド（約2700万円）が犯罪者の口座に送金されてしまいました。 内蔵センサーで通話盗聴 米ペンシルバニア州立大がリスク報告 本記事を読むにはAIDBのアカウントが必要です。ログイン 無料会員登録※ログイン/初回登録後、下記ボタンを押してください。 ■サポートのお願い AIDBを便利だと思っていただける方に、任意の金額でサポートしていただけますと幸いです。 AI新着論文を自動で取得し、日本語サマリーを毎日メールで受け取るサービスに申し込みが殺到しています。 毎日新しく出版されるAIの論文にキャッチアップするのは、「手間がかかる」「読解が難しい」といった問題あります。 AIDBは、オートで新着論文の探索を行い、❶論文情報❷日本語サマリーを複数掲載するニュースレターサービスを行っています。 ■サービス概要 ① AI新着論文の情報を毎日5件自動で収集 ② 論文のサマリーを記載 ③ キーワードをカスタマイズ可能 ④ 受け取り時間帯を指定可能 下記のフォームから簡単に申し込みが開始できます。 価格は現在¥500/月で、3日間は無料でトライアルができます。 キーワードを詳細にカスタマイズしたり、受け取り時間帯を指定するには、こちらのページから申し込みを行なってください。 下記のボタンからトライアルを開始した場合、デフォルトの設定（生成AI関連の論文）でサービスをご提供します。 キーワードや時間帯のご変更は申し込み後も可能です。 ※初めの3日間は無料です。4日目から引き落としを開始いたします。 Δ Tweet Share Hatena