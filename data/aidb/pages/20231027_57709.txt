最終更新日：2023/10/27 GPT-4などの大規模言語モデル（LLM）はコード生成においても驚異的な成果を上げています。しかし、モデルが生成するコードは必ずしも完璧ではありません。そこで、DeepMindとUCバークレーの研究者らは新たなフレームワーク『SELF-DEBUGGING（セルフデバッギング）』を開発しました。 追加訓練なしでも、複数のベンチマークにおいて高いパフォーマンスを達成できる手法です。実行プロンプト（の例）は比較的シンプルで、多くのプログラミングタスクで容易に適用できます。 （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 参照論文情報 ・タイトル：Teaching Large Language Models to Self-Debug・著者：Xinyun Chen, Maxwell Lin, Nathanael Schärli, Denny Zhou・所属：Google DeepMind, UC Berkeley・URL：https://doi.org/10.48550/arXiv.2304.05128 本記事の関連研究：LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト 目次 Toggle 背景と課題1. LLMは初めから正確なコードを生成しない2. 追加訓練のコスト3. コードの理解と実行4. 外部フィードバックの依存フレームワークの方法論SELF-DEBUGGINGフレームワークの概要3つの主要なステップ性能の実験実験の目的と内容使用されたモデル実験の結果結果の詳細実装方法・実行プロンプト例プロンプトの成り立ちから説明具体的なプロンプト例デモンストレーション主な結論LLMに自己デバッグの能力を教えることで、コード生成の性能が向上するアプローチは、人間のフィードバックやユニットテストが不足している場合でも有用注意点ユニットテストの不足モデルの限界とバイアス追加の考慮点まとめ 背景と課題 1. LLMは初めから正確なコードを生成しない LLMは、コード生成においても優れた性能を示しています。自然言語からのコード生成やコード変換など、多くのプログラミングタスクでその能力が評価されています。しかし、複雑なプログラミングタスクにおいて、一度の試行で正確なコードを生成することは容易ではありません。 2. 追加訓練のコスト 既存の研究では、特定のタスクに対する性能を向上させるために、モデルの追加訓練が多く行われています。しかし、追加訓練は時間とコストがかかり、効率的ではありません。 3. コードの理解と実行 LLMは自然言語の指示に従う能力は高いものの、コードの実行に関する理解は限定的だと言われています。例えば、問題の説明にユニットテスト（※）が提供されていても、生成されたプログラムが必ずしも正確であるわけではありません。 ※ユニットテストとは、プログラムの一部（通常は関数やメソッドなどの「ユニット」）が期待通りに動作するかを確認するためのテスト手法です。コードの各部分が正確に動作するかを独立して検証することで、全体としてのプログラムの品質を高めます。 4. 外部フィードバックの依存 多くの場合、LLMは外部のフィードバック（例えばユニットテストや人間による指示）がないと、生成したコードの正確性を確認することが難しいとされています。 このような背景と課題を解決するために研究者らが考案したのが「SELF-DEBUGGING」フレームワークです。 本記事の関連研究：GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク『LogiCoT』と実行プロンプト フレームワークの方法論 SELF-DEBUGGINGフレームワークの全体的な構造と動作を示す図 SELF-DEBUGGINGフレームワークの概要 研究者らは、LLMが自ら生成したプログラムをデバッグできるようにする新しいフレームワーク、SELF-DEBUGGINGを考案しました。特別な追加訓練なしで、既存のLLMに適用可能です。このフレームワークの一回のデバッグサイクルは、以下の3つのステップで構成されています。 3つの主要なステップ 1. 生成（Generation） 最初のステップでは、問題の説明を受けて、モデルは候補となるプログラムを予測します。このステップは、基本的にはコード生成のフェーズとなります。 2. 説明（Explanation） 次に、モデルは生成したプログラムに対して説明を行います。生成されたプログラムが何をしているのか、どのようなロジックに基づいているのかを説明するステップです。自然言語で行われる場合もありますが、サンプル入力に対する実行トレースを生成する場合もあります。 3. フィードバック（Feedback） 最後のステップでは、生成されたコードの正確性に関するセルフフィードバックメッセージが生成されます。このフィードバックは、基本的にはモデル自体によって生成されますが、外部のユニットテストと連携させた場合は、外部から生成される場合もあります。 このフレームワークは、いわゆる「ラバーダック・デバッグ」のようなスタイルを踏襲しています。プログラマがコードを一行一行説明することで、バグを特定する手法です。 フィードバックメッセージは、予測が正確であるか、許容されるデバッグターンの最大数に達した場合に、デバッギングプロセスを終了します。 本記事の関連研究：LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト 性能の実験 SELF-DEBUGGINGフレームワークがテキストからSQLを生成するタスクにどのように適用されるかを示す図 （自社サービス広告②）AIDBのリサーチを貴社のニーズに合わせてサブスクしませんか？ 実験の目的と内容 研究者らは、SELF-DEBUGGINGフレームワークの性能を評価するために複数の実験を行っています。以下の3つの主要なタスクで評価が行われました。 テキストからSQLを生成するタスク（使用データセット：Spider） C++からPythonへのコード変換（使用ツール：TransCoder） テキストからPythonを生成するタスク（使用データセット：MBPP） 下図はテキストからSQLクエリを生成するためのSELF-DEBUGGINGプロンプトの一例です。 （自社サービス広告③）AIDBで貴社のサービスをブランディングしませんか？ 使用されたモデル 実験には、GPT-4とGPT-3.5が使用されました。 本記事の関連研究：メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 TransCoderデータセットを用いた実験の一例 実験の結果 SELF-DEBUGGINGフレームワークは、いくつかのコード生成ベンチマークで最先端の性能を達成しました。また、コードの説明を用いることで、ベースライン性能が2-3%改善されました。さらに、ユニットテストを用いることで、最大で12%の精度が向上しました。 結果の詳細 テキストからSQLを生成するタスク（Spiderデータセット） SELF-DEBUGGINGフレームワークは、異なる初期サンプル数でもその効果を発揮しました。通常のベースライン手法で16個のサンプルを用いた場合の精度と、SELF-DEBUGGINGを適用した場合の精度が同等であることが確認されました。よって、少ないサンプル数でもSELF-DEBUGGINGが高い性能を維持できることを示されました。 C++からPythonへコード変換を行うタスク（TransCoder） ユニットテストとコード説明を組み合わせることで、デバッグの性能が向上しました。コード説明だけでも、サンプル数に関わらず2-3%の一貫した性能向上が見られました。 テキストからPythonを生成するタスク（MBPP） ユニットテストの実行を活用することで、実行トレースのフィードバックが6%の性能向上をもたらしました。 SELF-DEBUGGINGが一貫して性能を向上させることを示す結果の表 実験結果から、LLMが自ら生成したプログラムをデバッグする能力を高めることができるSELF-DEBUGGINGフレームワークの有効性が確認されました。また、ユニットテストとコード説明を活用することで、複数のタスクにおいて顕著な性能向上が見られました。 本記事の関連研究：LLMに非線形的な思考を与えてCoTを上回る性能を引き出す手法『IEP』と実行プロンプト CoTと組合せでさらに強力になる場合も 実装方法・実行プロンプト例 プロンプトの成り立ちから説明 プロンプトは、ユーザーとLLMが対話する際の指示や質問を形成するテキストフレーズです。モデルに対して特定のタスクを明確に指示するためのもので、その形式や内容はタスクの性質に応じて調整されます。本研究においては「SELF-DEBUGGING」フレームワークで重要な役割を果たします。 論文では、プロンプトがいくつかの基本的なステップに分けられることが示されています。具体的には、プロンプトは通常、以下のようなステップで構成されます。 生成（Generation）: ユーザーが何を行いたいのかを指定し、LLMに対してコードや解答を生成するように指示します。 説明（Explanation）: 生成されたコードや解答が何をするのかをLLMに説明させます。 フィードバック（Feedback）: 生成されたコードや解答の正確性を評価し、必要に応じて修正を指示します。 上記ステップは、ユーザーとLLM、場合によっては外部のツールとの間で行われます。 具体的なプロンプト例 以下は、この論文を基に具現化したプロンプトの例です。 ユーザー： 〜〜〜が行いたいです。 この問題に対する〜〜〜を生成してください。 LLM： 〜〜〜 ユーザー： 生成した〜〜〜が何をするのか説明してください。 LLM： 〜〜〜 ユーザー： 生成した〜〜〜は正確ですか？不正確であれば、何が問題か説明してください。 論文に基づいて生成されたプロンプトは、非常にシンプルで一見「当たり前」と思えるものですが、むしろそのシンプルさがSELF-DEBUGGINGフレームワークにおいて重要です。LLMが生成したコードを自動的にデバッグする能力を効率的に持たせることが目的であるためです。LLMに対して何を生成するか（生成）、その生成物が何をするのか（説明）、そしてその生成物が正確かどうか（フィードバック）を問い合わせることが実現すれば、プロンプトはシンプルでいいのです。 デモンストレーション ユーザー：テキストからSQLを生成したいです。問題は次のとおりです："studentsテーブルから、年齢が20歳以上の学生の名前をリストするSQLを生成してください。" この問題に対するSQLを生成してください。 LLM：SELECT name FROM students WHERE age > 20; ユーザー：生成したSQLが何をするのか説明してください。 LLM：このSQLクエリは、"students"というテーブルから、年齢が20歳よりも大きいすべての学生の名前を選択します。 ユーザー：生成したSQLは正確ですか？不正確であれば、何が問題か説明してください。 LLM：一点、誤りがありました。問題の説明には年齢が"20歳以上"と指定されていましたが、生成したSQLは"20歳より大きい"となっています。修正が必要です。 修正したSQLは SELECT name FROM students WHERE age >= 20; です。 本記事の関連研究：LLMに非線形的な思考を与えてCoTを上回る性能を引き出す手法『IEP』と実行プロンプト CoTと組合せでさらに強力になる場合も 主な結論 ユニットテストの実行を含むSELF-DEBUGGINGは顕著な改善が見られた様子 SpiderデータセットにおいてCodexを用いた自己デバッグ（SELF-DEBUGGING）の効果を詳細に分析した結果 この研究の主な結論は以下の通りです。 LLMに自己デバッグの能力を教えることで、コード生成の性能が向上する 研究者らは、LLMに自己デバッグの能力を教えることで、コード生成における性能を向上させることができると結論づけています。本アプローチは、特定のベンチマークにおいて最先端の性能を達成しています。Spiderデータセットで2-3%、TransCoderとMBPPで最大で12%の精度向上が確認されました。 アプローチは、人間のフィードバックやユニットテストが不足している場合でも有用 この研究では、人間のフィードバックやユニットテストが不足している場合でも、LLMが自らの生成したコードをデバッグできるようになると、その性能が向上することが示されました。これは、コード生成だけでなく、他の多くのタスクにも応用可能な有望な結果です。 注意点 この研究には、いくつかの重要な注意点があります。 ユニットテストの不足 論文によると、ユニットテストが提供されていない場面では、生成されたプログラムの正確性を確認するのは困難になります。モデルは「ラバーダック・デバッグ」に依存する可能性が高くなります。この点は、モデルを実用的な環境で使用する際に特に考慮すべきです。 モデルがコードの正確性を完全に自分自身で推測する必要がある場合に、ユニットテストの実行を含まない時の限定的な効果を示す表 モデルの限界とバイアス LLMは、コードの実行に関する限定的な理解しか持っていないと指摘されています。モデルが生成したプログラムが必ずしも正確であるわけではなく、モデルのバイアスが結果に影響を与える可能性も考慮する必要があります。 追加の考慮点 論文では、TranscoderとMBPPでの成功例の60-70%が、初めての誤ったコードが正しいものに非常に近い場合に出力の不一致エラーを修正しています。モデルが対処できるエラーのタイプが限定されている可能性があるとも考えられます。 実際のプロジェクトや研究でフレームワークを使用する際には、上記の制限と課題を理解しておくことが非常に重要です。ユニットテストや人間によるフィードバックが不足している環境では、注意深くモデルの出力を評価する必要があります。 まとめ この記事では、DeepMindとUCバークレーの研究者によって開発された新しいフレームワーク、SELF-DEBUGGINGについて詳しく解説しました。このフレームワークは、大規模言語モデル（LLM）にコード生成とデバッグの能力を付与するもので、生成、説明、フィードバックの3つのステップで動作します。追加訓練なしで複数のベンチマークで優れた性能を示していますが、ユニットテストの不足やモデルの限界も考慮する必要があります。 