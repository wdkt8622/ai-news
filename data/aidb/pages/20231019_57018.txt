Tweet Share Hatena 大規模言語モデル（LLM）は、質問応答、翻訳、テキスト要約など、さまざまなNLPタスクで優れた性能を発揮しています。しかし、モデルはしばしば正確な事実知識を捉えるのが難しく、根拠のない回答を生成することあります。この問題を解決するために、Amazonなどの研究者らが『Graph Neural Prompting（GNP）』という新しいフレームワークを考案しました。このフレームワークは、LLMにナレッジグラフ（知識グラフ）を連携させ、タスク遂行能力を大幅に向上させるものです。 （自社サービス広告①）自分好みの新着論文サマリーを毎日受け取りませんか？ 従来の方法では、モデルに学習データを追加するためには高いコストがかかりました。しかし、GNPを用いることで、より低いコストで高い成果を得ることができます。さらに、この方法はカスタマイズが非常に柔軟であり、特定のドメインや業界に合わせて調整することが可能です。 この記事では、この興味深い研究について詳しく解説していきます。 参照論文情報 ・タイトル：Graph Neural Prompting with Large Language Models・著者：Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang, Nitesh V. Chawla, Panpan Xu・所属：University of Notre Dame, Amazon・URL：https://doi.org/10.48550/arXiv.2309.15427 従来の課題と背景 LLMの限界と課題 LLMは、質問応答などの多くのタスクで優れた性能を発揮しています。しかし、事実に基づいた正確な知識を正確に捉える能力には限界があります。LLMは基本的には訓練データに基づいて予測を行うため、訓練データに応じて誤った情報や偏見を出力するリスクはゼロではありません。 コストの問題 LLMを知識グラフ（KG）で強化するというアイデアは以前から存在していますが、その実装には大きくコストがかかります。LLMには多数のパラメータがあり、調整するためには膨大な計算リソースが必要です。知識グラフとテキストデータを共同で訓練する場合には多くの資源が必要となります。 既存のアプローチとその限界 既存のアプローチでは、知識グラフから得られるトリプル（主語、述語、目的語の組み合わせ）をLLMに直接供給する方法があります。しかし、知識グラフがさまざまな外部コンテキストを含む可能性があり、その結果として大量のノイズを導入する可能性があります。 以上のような背景から、本研究では、知識グラフを事前学習済みLLMに効果的に統合する新しい方法を提案しています。 本研究の関連研究：LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト GNPのフレームワーク Amazonなどの研究者らは、外部の知識グラフとLLMをシームレスに接続するフレームワーク『Graph Neural Prompting（GNP）』を考案しました。以下の主要なコンポーネントで構成されています。 標準的なグラフニューラルネットワークエンコーダ クロスモダリティプーリングモジュール ドメインプロジェクタ 自己教師付きリンク予測オブジェクト 1. グラフニューラルネットワークエンコーダ GNPは、まずグラフニューラルネットワーク（GNN）を用いて、知識グラフ内の複雑な情報をエンティティ/ノードの埋め込みにエンコードします。知識グラフの各エンティティや関係性が数値ベクトルとして表現され、後続の処理で効率的に扱えるようにするための要素です。 2. クロスモダリティプーリングモジュール 次に、クロスモダリティプーリングモジュールがテキスト入力と関連する最も関連性の高いノードの埋め込みを特定します。この要素により、テキストと知識グラフの間で最も重要な情報が統合され、一つのグラフレベルの埋め込みにまとめられます。 2. ドメインプロジェクタ このグラフレベルの埋め込みは、ドメインプロジェクタを通して、テキストとグラフの間の固有の違いを橋渡しします。この要素により、両者の情報が効果的に統合され、より高度なタスク遂行が可能になります。 4. 自己教師付きリンク予測オブジェクト 最後に、自己教師付きリンク予測オブジェクトがモデルの性能をさらに向上させるために導入されます。このオブジェクトは、知識グラフ内のエンティティ間の関係を予測することで、モデルがより正確な知識を獲得できるようにします。 GNPのこれらのコンポーネントは、連携してLLMのパフォーマンスを大幅に向上させる役割を果たします。特に、このフレームワークは、既存のLLMに対してプラグアンドプレイ可能であり、柔軟なカスタマイズと効率的な実装が可能です。 本研究の関連研究：LLMに自身のハルシネーション（幻覚）を「自覚」させ、減らす方法 性能評価実験 本記事を読むにはAIDBのアカウントが必要です。ログイン 無料会員登録※ログイン/初回登録後、下記ボタンを押してください。 （自社サービス広告②）AIDBのリサーチを貴社のニーズに合わせてサブスクしませんか？ ■サポートのお願い AIDBを便利だと思っていただける方に、任意の金額でサポートしていただけますと幸いです。 AI新着論文を自動で取得し、日本語サマリーを毎日メールで受け取るサービスに申し込みが殺到しています。 毎日新しく出版されるAIの論文にキャッチアップするのは、「手間がかかる」「読解が難しい」といった問題あります。 AIDBは、オートで新着論文の探索を行い、❶論文情報❷日本語サマリーを複数掲載するニュースレターサービスを行っています。 ■サービス概要 ① AI新着論文の情報を毎日5件自動で収集 ② 論文のサマリーを記載 ③ キーワードをカスタマイズ可能 ④ 受け取り時間帯を指定可能 下記のフォームから簡単に申し込みが開始できます。 価格は現在¥500/月で、3日間は無料でトライアルができます。 キーワードを詳細にカスタマイズしたり、受け取り時間帯を指定するには、こちらのページから申し込みを行なってください。 下記のボタンからトライアルを開始した場合、デフォルトの設定（生成AI関連の論文）でサービスをご提供します。 キーワードや時間帯のご変更は申し込み後も可能です。 ※初めの3日間は無料です。4日目から引き落としを開始いたします。 Δ Tweet Share Hatena